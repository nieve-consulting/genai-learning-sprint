# Quiz â€“ Introduction to Deep Learning

> ðŸš¦ **Instructions:** Fill out this quiz by marking the correct option. An `x` within the square brackets represents a marked checkbox. For example, `[ ]`. If the question allows multiple answers, select all the correct options.

- Name: *Fill in your name*
- Email: *Fill in your email address*

---

**1.** What is a Neural Network inspired by?
- [ ] A computer algorithm
- [ ] A set of mathematical functions
- [ ] The way biological neural networks in the human brain process information
- [ ] A flowchart of operations

**2.** In a neural network, which layer is responsible for receiving the input data?
- [ ] Hidden Layer
- [ ] Output Layer
- [ ] Input Layer
- [ ] Activation Layer

**3.** What is a perceptron in the context of neural networks?
- [ ] A type of activation function
- [ ] The simplest form of a neural network that models a single neuron
- [ ] A deep learning model with multiple layers
- [ ] A method for optimizing neural networks

**4.** Which of the following functions is typically used as the activation function in a perceptron?
- [ ] ReLU
- [ ] Heaviside step function
- [ ] Sigmoid function
- [ ] Softmax function

**5.** Why is the bias term important in a perceptron?
- [ ] It increases the learning rate.
- [ ] It allows the perceptron to process non-linear data.
- [ ] It allows the perceptron to learn a decision boundary that does not pass through the origin.
- [ ] It reduces the complexity of the model.

**6.** What is the primary limitation of a perceptron?
- [ ] It cannot process large datasets.
- [ ] It is computationally expensive.
- [ ] It can only model linearly separable functions.
- [ ] It cannot be used for binary classification.

**7.** Which type of neural network is capable of modeling complex functions, including the XOR problem?
- [ ] Single-layer perceptron
- [ ] Multilayer Perceptron (MLP)
- [ ] Recurrent Neural Network (RNN)
- [ ] Convolutional Neural Network (CNN)

**8.** What is the purpose of forward propagation in a neural network?
- [ ] To calculate the loss function
- [ ] To compute the output of the network by passing data from input to output layers
- [ ] To update the weights of the network
- [ ] To initialize the parameters of the network

**9.** In the context of backpropagation, what is the gradient used for?
- [ ] To initialize the model weights
- [ ] To measure the accuracy of the model
- [ ] To update the weights to minimize the loss function
- [ ] To calculate the forward pass

**10.** Which activation function is commonly used in the output layer of a neural network for multi-class classification tasks?
- [ ] Sigmoid
- [ ] ReLU
- [ ] Softmax
- [ ] Tanh

**11.** In the context of a neural network, what does backpropagation primarily involve?
- [ ] Updating the biases of the network
- [ ] Calculating the output of each layer
- [ ] Adjusting the weights based on the error gradient
- [ ] Forwarding the inputs through the network

**12.** What is the purpose of the softmax function in a neural network?
- [ ] To convert raw scores into probabilities for multi-class classification
- [ ] To introduce non-linearity into the model
- [ ] To minimize the loss function
- [ ] To prevent the vanishing gradient problem

**13.** Which of the following statements is true about Multilayer Perceptrons (MLPs)?
- [ ] MLPs can only approximate linear functions
- [ ] MLPs require the use of the Heaviside step function as the activation function
- [ ] MLPs can model complex, non-linear functions due to their multiple layers
- [ ] MLPs do not require forward propagation for training

**14.** In the context of neural networks, what does "epoch" refer to?
- [ ] A single iteration through the entire training dataset during the training process
- [ ] The number of hidden layers in the neural network
- [ ] The amount of data processed in one batch
- [ ] The final output layer of the network

**15.** What is the purpose of using a learning rate in gradient descent optimization?
- [ ] To determine the number of epochs required for training
- [ ] To control the step size at each iteration while moving towards a minimum of the loss function
- [ ] To reduce the training time by skipping some iterations
- [ ] To adjust the modelâ€™s complexity automatically
