<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.547">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>tensorflow-playground</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="03-tensorflow-playground_files/libs/clipboard/clipboard.min.js"></script>
<script src="03-tensorflow-playground_files/libs/quarto-html/quarto.js"></script>
<script src="03-tensorflow-playground_files/libs/quarto-html/popper.min.js"></script>
<script src="03-tensorflow-playground_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="03-tensorflow-playground_files/libs/quarto-html/anchor.min.js"></script>
<link href="03-tensorflow-playground_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="03-tensorflow-playground_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="03-tensorflow-playground_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="03-tensorflow-playground_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="03-tensorflow-playground_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="tensorflow-playground-activity" class="level1">
<h1>TensorFlow Playground Activity</h1>
<blockquote class="blockquote">
<p>üö¶ <strong>Instructions:</strong> Fill out this quiz by marking the correct option(s). In order to save your answers, use your browser‚Äôs <code>Print to PDF</code> function. (<a href="https://libguides.rowan.edu/c.php?g=248114&amp;p=4710174">Chrome instructions.</a>)</p>
</blockquote>
<p>TensorFlow Playground is an interactive tool that allows you to visualize and experiment with neural networks in your browser. It‚Äôs a great way to understand the impact of different hyperparameters, network architectures, and data patterns on model performance. In this activity, you will explore key concepts related to neural networks using TensorFlow Playground.</p>
<hr>
<section id="part-1-important-concepts" class="level2">
<h2 class="anchored" data-anchor-id="part-1-important-concepts"><strong>Part 1: Important Concepts</strong></h2>
<p><strong>1. Neural Networks:</strong></p>
<ul>
<li><strong>Definition:</strong> A computational model inspired by the human brain, consisting of layers of nodes (neurons) that process data and learn from it.</li>
<li><strong>Components:</strong>
<ul>
<li><strong>Input Layer:</strong> Receives the input data.</li>
<li><strong>Hidden Layers:</strong> Perform computations and feature transformations.</li>
<li><strong>Output Layer:</strong> Produces the final prediction or classification.</li>
</ul></li>
</ul>
<p><strong>2. Activation Functions:</strong></p>
<ul>
<li><strong>Definition:</strong> Functions that determine whether a neuron should be activated or not. They introduce non-linearity into the model.</li>
<li><strong>Common Types:</strong>
<ul>
<li><strong>ReLU (Rectified Linear Unit):</strong> <span class="math inline">\(f(x) = max(0, x)\)</span></li>
<li><strong>Sigmoid:</strong> <span class="math inline">\(f(x) = 1 / (1 + e^-x)\)</span></li>
<li><strong>Tanh:</strong> <span class="math inline">\(f(x) = (e^x - e^-x) / (e^x + e^-x)\)</span></li>
</ul></li>
</ul>
<p><strong>3. Learning Rate:</strong></p>
<ul>
<li><strong>Definition:</strong> A hyperparameter that controls how much to adjust the model‚Äôs weights with respect to the loss gradient.</li>
<li><strong>Impact:</strong> Too high can cause divergence, too low can make the training process slow.</li>
</ul>
<p><strong>4. Regularization:</strong></p>
<ul>
<li><strong>Definition:</strong> Techniques used to prevent overfitting by penalizing large weights.</li>
<li><strong>Types:</strong>
<ul>
<li><strong>L1 Regularization:</strong> Adds a penalty equal to the absolute value of the magnitude of coefficients.</li>
<li><strong>L2 Regularization:</strong> Adds a penalty equal to the square of the magnitude of coefficients.</li>
</ul></li>
</ul>
<p><strong>5. Overfitting vs.&nbsp;Underfitting:</strong></p>
<ul>
<li><strong>Overfitting:</strong> When the model performs well on training data but poorly on new, unseen data.</li>
<li><strong>Underfitting:</strong> When the model is too simple to capture the underlying pattern of the data.</li>
</ul>
<p><strong>6. Epochs:</strong></p>
<ul>
<li><strong>Definition:</strong> One complete pass of the training dataset through the neural network.</li>
<li><strong>Impact:</strong> More epochs allow the model to learn better but can also lead to overfitting.</li>
</ul>
<p><strong>7. Data Patterns:</strong></p>
<ul>
<li><strong>Understanding:</strong> The shape and distribution of your data can significantly affect the neural network‚Äôs ability to learn. Common patterns include linear, spiral, circular, and XOR.</li>
</ul>
<p><strong>8. Weight Initialization:</strong></p>
<ul>
<li><strong>Definition:</strong> The initial values assigned to the weights in the neural network.</li>
<li><strong>Impact:</strong> Proper weight initialization can lead to faster convergence and better overall performance.</li>
</ul>
<p><strong>9. Batch Size:</strong></p>
<ul>
<li><strong>Definition:</strong> The number of training examples used to calculate the gradient at each iteration.</li>
<li><strong>Impact:</strong> A smaller batch size can lead to noisier updates but may generalize better, while a larger batch size provides a smoother gradient but might require more epochs.</li>
</ul>
<hr>
</section>
<section id="part-2-exercises" class="level2">
<h2 class="anchored" data-anchor-id="part-2-exercises"><strong>Part 2: Exercises</strong></h2>
<blockquote class="blockquote">
<p>üí° <strong>Tip:</strong> You can save your TensorFlow Playground experiments by copying the URL from your browser‚Äôs address bar. The URL contains all the settings of your current experiment, including the network architecture, activation functions, data set, learning rate, and other parameters. You can save it, or share it with others to revisit or collaborate on the same experiment later.</p>
</blockquote>
<section id="exercise-1-understanding-activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="exercise-1-understanding-activation-functions"><strong>Exercise 1: Understanding Activation Functions</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Experiment with different activation functions and observe their impact on model performance.</li>
<li><strong>Steps:</strong>
<ul>
<li>Open <a href="https://playground.tensorflow.org/">TensorFlow Playground</a>.</li>
<li>Use a dataset with a clear pattern (e.g., ‚ÄúCircle‚Äù or ‚ÄúXOR‚Äù).</li>
<li>Try different activation functions (<span class="math inline">\(ReLU\)</span>, <span class="math inline">\(Sigmoid\)</span>, <span class="math inline">\(Tanh\)</span>) in the hidden layers.</li>
<li>Observe how the decision boundary changes and how well the model fits the data.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>How does the decision boundary change with different activation functions?</li>
<li>Which activation function provided the best fit for the dataset?</li>
</ul></li>
</ol>
</section>
<section id="exercise-2-exploring-learning-rates" class="level3">
<h3 class="anchored" data-anchor-id="exercise-2-exploring-learning-rates"><strong>Exercise 2: Exploring Learning Rates</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Understand the importance of learning rates in training neural networks.</li>
<li><strong>Steps:</strong>
<ul>
<li>Select a complex dataset (e.g., ‚ÄúSpiral‚Äù).</li>
<li>Set up a neural network with 2 hidden layers and several neurons.</li>
<li>Experiment with different learning rates (e.g., <code>0.01</code>, <code>0.1</code>, <code>0.3</code>).</li>
<li>Observe how the model‚Äôs convergence speed and accuracy are affected.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>What happened when the learning rate was too high or too low?</li>
<li>How did the learning rate affect the model‚Äôs ability to generalize to unseen data?</li>
</ul></li>
</ol>
</section>
<section id="exercise-3-regularization-techniques" class="level3">
<h3 class="anchored" data-anchor-id="exercise-3-regularization-techniques"><strong>Exercise 3: Regularization Techniques</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Explore how regularization affects model performance and prevents overfitting.</li>
<li><strong>Steps:</strong>
<ul>
<li>Choose a dataset prone to overfitting (e.g., ‚ÄúHigh noise‚Äù).</li>
<li>Set up a neural network with multiple hidden layers.</li>
<li>Experiment with different regularization settings (<code>L1</code>, <code>L2</code>) and observe their impact.</li>
<li>Compare results with and without regularization.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>How did regularization affect the model‚Äôs complexity and performance?</li>
<li>Which regularization technique was most effective in preventing overfitting?</li>
</ul></li>
</ol>
</section>
<section id="exercise-4-impact-of-epochs-on-training" class="level3">
<h3 class="anchored" data-anchor-id="exercise-4-impact-of-epochs-on-training"><strong>Exercise 4: Impact of Epochs on Training</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Observe how the number of epochs influences model performance.</li>
<li><strong>Steps:</strong>
<ul>
<li>Select a simple dataset (e.g., ‚ÄúCircle‚Äù).</li>
<li>Set up a basic neural network with 1 or 2 hidden layers.</li>
<li>Train the model with varying numbers of epochs (e.g., <code>10</code>, <code>50</code>, <code>100</code>).</li>
<li>Observe the model‚Äôs performance on both training and test sets.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>What changes occurred in the decision boundary as the number of epochs increased?</li>
<li>Did you notice any signs of overfitting with more epochs?</li>
</ul></li>
</ol>
</section>
<section id="exercise-5-experimenting-with-weight-initialization" class="level3">
<h3 class="anchored" data-anchor-id="exercise-5-experimenting-with-weight-initialization"><strong>Exercise 5: Experimenting with Weight Initialization</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Understand the importance of weight initialization on the convergence of a neural network.</li>
<li><strong>Steps:</strong>
<ul>
<li>Select a dataset with moderate complexity (e.g., ‚ÄúGaussian‚Äù).</li>
<li>Set up a neural network with 2 hidden layers.</li>
<li>Experiment with different weight initialization methods (e.g., small random values, zeros).</li>
<li>Observe the training process and convergence speed.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>How did different initialization methods affect the learning process?</li>
<li>Which initialization method resulted in faster or more stable convergence?</li>
</ul></li>
</ol>
</section>
<section id="exercise-6-analyzing-the-effect-of-batch-size" class="level3">
<h3 class="anchored" data-anchor-id="exercise-6-analyzing-the-effect-of-batch-size"><strong>Exercise 6: Analyzing the Effect of Batch Size</strong></h3>
<ol type="1">
<li><strong>Objective:</strong> Explore how different batch sizes affect model training and generalization.</li>
<li><strong>Steps:</strong>
<ul>
<li>Select a dataset with a non-linear pattern (e.g., ‚ÄúSpiral‚Äù).</li>
<li>Set up a neural network with 3 hidden layers.</li>
<li>Train the model using different batch sizes (e.g., <code>1</code>, <code>10</code>, <code>100</code>).</li>
<li>Compare the performance, speed of convergence, and generalization ability of the model.</li>
</ul></li>
<li><strong>Questions:</strong>
<ul>
<li>How did the model‚Äôs performance vary with different batch sizes?</li>
<li>Did smaller or larger batch sizes lead to better generalization?</li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="part-3-quiz" class="level2">
<h2 class="anchored" data-anchor-id="part-3-quiz"><strong>Part 3: Quiz</strong></h2>
<p><strong>1.</strong> What is the role of the activation function in a neural network?</p>
<ul class="task-list">
<li><label><input type="checkbox">To determine the learning rate</label></li>
<li><label><input type="checkbox">To decide whether a neuron should be activated</label></li>
<li><label><input type="checkbox">To control the number of layers in the network</label></li>
<li><label><input type="checkbox">To measure the error rate during training</label></li>
</ul>
<p><strong>2.</strong> How does regularization help prevent overfitting?</p>
<ul class="task-list">
<li><label><input type="checkbox">By increasing the number of epochs</label></li>
<li><label><input type="checkbox">By adding noise to the input data</label></li>
<li><label><input type="checkbox">By penalizing large weights in the model</label></li>
<li><label><input type="checkbox">By reducing the learning rate</label></li>
</ul>
<p><strong>3.</strong> What is a potential consequence of setting the learning rate too high?</p>
<ul class="task-list">
<li><label><input type="checkbox">The model will converge too quickly</label></li>
<li><label><input type="checkbox">The model will learn the data perfectly</label></li>
<li><label><input type="checkbox">The model might diverge and fail to learn</label></li>
<li><label><input type="checkbox">The model will underfit the data</label></li>
</ul>
<p><strong>4.</strong> How many epochs should you train a model for to avoid overfitting?</p>
<ul class="task-list">
<li><label><input type="checkbox">As many as possible</label></li>
<li><label><input type="checkbox">Enough to achieve low training error, but not too many that test error increases</label></li>
<li><label><input type="checkbox">Only one epoch</label></li>
<li><label><input type="checkbox">Until the model reaches 100% accuracy on training data</label></li>
</ul>
<p><strong>5.</strong> What impact does a larger batch size have on training a neural network?</p>
<ul class="task-list">
<li><label><input type="checkbox">It increases the noise in gradient updates</label></li>
<li><label><input type="checkbox">It leads to smoother gradient updates</label></li>
<li><label><input type="checkbox">It requires fewer epochs to converge</label></li>
<li><label><input type="checkbox">It always improves model performance</label></li>
</ul>
<p><strong>6.</strong> Why is proper weight initialization important in neural networks?</p>
<ul class="task-list">
<li><label><input type="checkbox">To avoid vanishing gradients</label></li>
<li><label><input type="checkbox">To ensure that all neurons in a layer are identical</label></li>
<li><label><input type="checkbox">To speed up the training process</label></li>
<li><label><input type="checkbox">To reduce the number of epochs required</label></li>
</ul>
<p><strong>7.</strong> Which data pattern would be most challenging for a simple neural network to learn?</p>
<ul class="task-list">
<li><label><input type="checkbox">Linear</label></li>
<li><label><input type="checkbox">Circular</label></li>
<li><label><input type="checkbox">Spiral</label></li>
<li><label><input type="checkbox">Gaussian</label></li>
</ul>
<p><strong>8.</strong> What happens if you do not use an activation function in the hidden layers of a neural network?</p>
<ul class="task-list">
<li><label><input type="checkbox">The network becomes a linear model</label></li>
<li><label><input type="checkbox">The network overfits more easily</label></li>
<li><label><input type="checkbox">The network cannot converge</label></li>
<li><label><input type="checkbox">The network requires fewer epochs to train</label></li>
</ul>
<p><strong>9.</strong> Which of the following is a symptom of underfitting?</p>
<ul class="task-list">
<li><label><input type="checkbox">High accuracy on training data but low accuracy on test data</label></li>
<li><label><input type="checkbox">Low accuracy on both training and test data</label></li>
<li><label><input type="checkbox">High accuracy on both training and test data</label></li>
<li><label><input type="checkbox">Model performs well on complex patterns but not on simple ones</label></li>
</ul>
<p><strong>10.</strong> When experimenting with TensorFlow Playground, which hyperparameter has the most direct impact on the speed of convergence?</p>
<ul class="task-list">
<li><label><input type="checkbox">Number of layers</label></li>
<li><label><input type="checkbox">Regularization type</label></li>
<li><label><input type="checkbox">Learning rate</label></li>
<li><label><input type="checkbox">Batch size</label></li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>